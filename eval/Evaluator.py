import pandas as pd
import numpy as np
from tqdm import tqdm
from utils.SearchHanzi import Hanzi
from utils.InfoProcess import GetMoreInfo
from utils.preprocess_ori_data import trans_dy, keep_chinese, keep_chinese_and_pipe
import argparse
from utils.base_param import *

params = BaseParam()
from utils.LLMs import *
from prompts.promptsMetrics import MetricsPromptDesign
from utils.ChineseNames import ChineseNames

mpd = MetricsPromptDesign()
llm = Kimi()
df_p = pd.read_csv(params.poems_all_v1_os + 'poems_All.csv', low_memory=False)
df_p = df_p.fillna('')
df_p['cont_text'] = df_p['content'].apply(lambda x: re.sub(r'[^\u4e00-\u9fa5]', '', x))
df_p.drop_duplicates(subset=['cont_text'], keep='first', inplace=True)
df_p['title_text'] = df_p['title'].apply(lambda x: re.sub(r'[^\u4e00-\u9fa5]', '', x))


class Evaluator:
    def __init__(self, user_query, gen_cont_all, gen_cont, exp):
        self.p_emoc = mpd.EMOC
        self.p_crc = mpd.CRC
        self.p_lc = mpd.LC
        self.p_acc = mpd.Acc
        self.user_query = user_query
        self.gen_cont_all = gen_cont_all
        self.gen_cont = gen_cont
        self.exp = exp

    def eval_EMOC(self):
        prompt_emoc = self.p_emoc.format(user_query=self.user_query, gen_cont=self.gen_cont, exp=self.exp)
        res, _ = getLlmRes(llm, prompt_emoc, 'è¯„ä¼°åˆ†æ•°')
        return res['è¯„ä¼°åˆ†æ•°']

    def eval_CRC(self):
        prompt_comp = self.p_crc.format(user_query=self.user_query, gen_cont=self.gen_cont, exp=self.exp)
        res, _ = getLlmRes(llm, prompt_comp, 'è¯„ä¼°åˆ†æ•°')
        return res['è¯„ä¼°åˆ†æ•°']

    def eval_LC(self):
        prompt_lc = self.p_lc.format(user_query=self.user_query, gen_cont=self.gen_cont, exp=self.exp)
        res, _ = getLlmRes(llm, prompt_lc, 'è¯„ä¼°åˆ†æ•°')
        return res['è¯„ä¼°åˆ†æ•°']

    def eval_Acc(self):
        def check_poems(poem_info):
            for p in poem_info:
                try:
                    tmp = p['é¢˜ç›®']
                except:
                    p['é¢˜ç›®'] = 'æ— '
                if p['é¢˜ç›®'] == 'æ— ' and p['è¯—äºº'] == 'æ— ' and p['æœä»£'] == 'æ— ' and p['è¯—å¥'] == 'æ— ':
                    continue
                title = keep_chinese(p['é¢˜ç›®']) if p['é¢˜ç›®'] != 'æ— ' else ''
                author = p['è¯—äºº'] if p['è¯—äºº'] != 'æ— ' else ''
                dynasty = trans_dy(p['æœä»£']) if p['æœä»£'] != 'æ— ' else ''
                content = keep_chinese_and_pipe(p['è¯—å¥']) if p['è¯—å¥'] != 'æ— ' else ''
                if '|' not in content:
                    # ç›´æ¥æ£€æŸ¥å¤è¯—çš„ä¿¡æ¯
                    df_ = df_p[(df_p['title_text'].str.contains(title))
                               & (df_p['author'].str.contains(author))
                               & (df_p['dynasty'].str.contains(dynasty))
                               & (df_p['cont_text'].str.contains(content))]
                else:
                    # æ£€æŸ¥è¯—å¥æ˜¯å¦å‡ºè‡ªåŒä¸€é¦–å¤è¯—
                    df_ = df_p[(df_p['title_text'].str.contains(title))
                               & (df_p['author'].str.contains(author))
                               & (df_p['dynasty'].str.contains(dynasty))]
                    con_li = content.split('|')
                    df_cont = pd.DataFrame()
                    for con in con_li:
                        if df_cont.shape[0] == 0:
                            df_cont = df_[(df_['cont_text'].str.contains(con))]
                        else:
                            df_tmp = df_[(df_['cont_text'].str.contains(con))]
                            tmp_ids = set(df_tmp.index.values.tolist())
                            cont_ids = set(df_cont.index.values.tolist())
                            if len(tmp_ids & cont_ids) > 0:
                                df_cont = df_cont.loc[list(tmp_ids & cont_ids)]
                    df_ = df_cont
                if df_.shape[0] == 0:
                    return False
            return True

        def check_wuxing(haw_info):
            if len(haw_info) == 0 or haw_info == 'æ— ':
                return True
            haw_dic = {}
            for i in haw_info:
                try:
                    haw_dic[i['å­—']] = i['äº”è¡Œ']
                except:
                    pass
            h_li = haw_dic.keys()
            hz = Hanzi()
            h_wuxing = {h: hz.getWuxingByHanzi(h) for h in h_li}
            for h in h_li:
                if haw_dic[h] != h_wuxing[h]:
                    return False
            return True

        def extract_date_time(query):
            # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ—¥æœŸï¼ˆå¦‚ï¼š2028å¹´1æœˆ15æ—¥ï¼‰
            date_pattern_year = r'(\d{4})å¹´'
            date_pattern_month = r'(\d{1,2})æœˆ'
            date_pattern_day = r'(\d{1,2})æ—¥'
            date_pattern_minute = r'(\d{1,2})åˆ†'
            date_pattern_second = r'(\d{1,2})ç§’'
            # åˆ†åˆ«å®šä¹‰åŒ¹é…å…·ä½“æ—¶é—´ç‚¹ï¼ˆå¦‚ï¼š3ç‚¹ã€6ç‚¹ï¼‰å’Œæ—¶é—´æ®µè¯´æ˜ï¼ˆå¦‚ï¼šåˆå¤œã€å‚æ™šï¼‰
            date_pattern_hour = r'(\d{1,2})ç‚¹'
            period_pattern = r'\d{1,2}æ—¥?(ä¸Šåˆ|ä¸­åˆ|ä¸‹åˆ|å‡Œæ™¨|æ™š|æ—©|å‚æ™š|æ™šä¸Š|åˆå¤œ)'
            # å¤„ç†å­£èŠ‚çš„ç®€å†™å’Œå®Œæ•´å½¢å¼
            season_pattern = r'å¹´(æ˜¥|å¤|ç§‹|å†¬)'
            # åŒ¹é…æ—¥æœŸ
            match_y = re.search(date_pattern_year, query)
            if match_y:
                year = int(match_y.group(1))
            else:
                year = '00'
            match_m = re.search(date_pattern_month, query)
            if match_m:
                month = int(match_m.group(1))
            else:
                month = '00'
            match_d = re.search(date_pattern_day, query)
            if match_d:
                day = int(match_d.group(1))
            else:
                day = '00'
            match_h = re.search(date_pattern_hour, query)
            if match_h:
                hour_ = int(match_h.group(1))
            else:
                hour_ = 00
            # åŒ¹é…æ—¶é—´æ®µè¯´æ˜
            hour_period_match = re.search(period_pattern, query)
            if hour_period_match:
                period = hour_period_match.group(1)
                # å¦‚æœåŒ¹é…åˆ°"å‚æ™š"ï¼Œå¹¶ä¸”æ—¶é—´å°äº12ï¼Œåˆ™æ—¶é—´åŠ 12å°æ—¶
                if period in ['ä¸‹åˆ', 'æ™š', 'å‚æ™š', 'æ™šä¸Š'] and hour_ < 12 and hour_ > 0:
                    hour_ += 12
                    # print(query)
            if hour_ == 0:
                hour_ = '00'
            match_m = re.search(date_pattern_minute, query)
            if match_m:
                minute = int(match_m.group(1))
            else:
                minute = '00'
            match_s = re.search(date_pattern_second, query)
            if match_s:
                second = int(match_s.group(1))
            else:
                second = '00'
            birth_date = f'{year}-{month}-{day}-{hour_}-{minute}-{second}'
            # åŒ¹é…å­£èŠ‚
            season_match = re.search(season_pattern, query)
            if season_match:
                season = season_match.group(1)
            else:
                season = None

            return birth_date, season

        def check_born(born_info):
            birth, season = extract_date_time(self.user_query)
            ef = GetMoreInfo(birth=birth, season=season)
            expand_info = ef.get_baby_info_new()
            acc_li = [1] * 6
            if born_info['ç”Ÿè‚–'] != 'æ— ' and expand_info['ç”Ÿè‚–'] != born_info['ç”Ÿè‚–']:
                acc_li[0] = 0
            if born_info['å­£èŠ‚'] != 'æ— ' and expand_info['å­£èŠ‚'][0] != born_info['å­£èŠ‚'][0]:
                acc_li[1] = 0
            if born_info['èŠ‚æ°”'] != 'æ— ' and expand_info['èŠ‚æ°”'] != born_info['èŠ‚æ°”']:
                acc_li[2] = 0
            if born_info['èŠ‚æ—¥'] != 'æ— ' and expand_info['èŠ‚æ—¥'] != born_info['èŠ‚æ—¥']:
                acc_li[3] = 0
            if born_info['å…«å­—'] != 'æ— ':
                gen_bz = keep_chinese(born_info['å…«å­—'])
                fact_bz = keep_chinese(expand_info['å…«å­—å’Œäº”è¡Œ'])
                if len(gen_bz) < len(fact_bz):
                    fact_bz = re.sub(r'\(.*?\)', '', expand_info['å…«å­—å’Œäº”è¡Œ']).strip()
                if gen_bz != fact_bz:
                    acc_li[4] = 0
            if born_info['äº”è¡Œç¼ºå¤±'] != 'æ— ':
                gen_wx = born_info['äº”è¡Œç¼ºå¤±'].split('|')
                gen_wx = [i for i in gen_wx if i != '']
                fact_wx = expand_info['äº”è¡Œç¼ºå¤±']
                if set(gen_wx) & set(fact_wx) != set(gen_wx):
                    acc_li[5] = 0
            return acc_li

        prompt_fa = self.p_acc.format(exp=self.exp)
        infos, _ = getLlmRes(llm, prompt_fa, 'å¤è¯—ä¿¡æ¯')
        f_poems = check_poems(poem_info=infos['å¤è¯—ä¿¡æ¯'])
        f_wuxing = check_wuxing(haw_info=infos['å­—å’Œäº”è¡Œ'])
        f_born = check_born(born_info=infos['å‡ºç”Ÿä¿¡æ¯'])
        f_poems = 1 if f_poems else 0
        f_wuxing = 1 if f_wuxing else 0
        f_li = [f_poems, f_wuxing]
        f_li.extend(f_born)
        return f_li

    def run(self):
        emoc = self.eval_EMOC()
        crc = self.eval_CRC()
        lc = self.eval_LC()
        acc = self.eval_Acc()
        return emoc, crc, lc, acc


def eval_Nov(name_li):
    '''
    ï¼ˆâˆšï¼‰NUğŸ‘†: Name uniqueness, åå­—ç‹¬ç‰¹æ€§ï¼Œ1~6è¶Šé«˜åˆ†è¶Šç‹¬ç‰¹ï¼ŒNU = 2 å’Œ 3 åˆ†åˆ«è¡¨ç¤º 1/100 å’Œ 1/1000 çš„äººåœ¨åå­—ä¸­ä½¿ç”¨äº†è¿™ä¸ªå­—ç¬¦ï¼ˆåœ¨ä»–ä»¬çš„å‡ºç”Ÿå¹´ä»½ï¼‰ã€‚
    ï¼ˆâˆšï¼‰CCUğŸ‘†: Character corpus uniqueness, å­—ç¬¦è¯­æ–™åº“ç‹¬ç‰¹æ€§1~6(åŸºäºå½“ä»£ä¸­æ–‡è¯­æ–™åº“ä¸­æŸä¸ªå­—ç¬¦çš„ä½¿ç”¨é¢‘ç‡æ¥è®¡ç®—çš„ç‹¬ç‰¹æ€§æŒ‡æ ‡ã€‚ä¸NUä¸åŒï¼ŒCCUè¡¡é‡çš„æ˜¯æ—¥å¸¸è¯­è¨€ä½¿ç”¨ä¸­å­—ç¬¦çš„æµè¡Œåº¦ï¼Œè€Œä¸æ˜¯åå­—ä¸­çš„ä½¿ç”¨é¢‘ç‡ã€‚)
    ï¼ˆâˆšï¼‰NVğŸ‘†: Name valence, åå­—æƒ…æ„Ÿä»·å€¼ åŸºäº16ä½ä¸­æ–‡è¯„ä»·è€…å¯¹2614ä¸ªåå­—å­—ç¬¦æ„ä¹‰çš„ç§¯æç¨‹åº¦çš„ä¸»è§‚è¯„åˆ†ï¼ˆ1åˆ°5åˆ†ï¼‰ã€‚ï¼ˆ1 =éå¸¸è´Ÿé¢ï¼Œ3 =ä¸­æ€§ï¼Œ5 =éå¸¸æ­£é¢ï¼‰
    ï¼ˆâˆšï¼‰NWğŸ‘†: Name warmth, åå­—æ¸©æš–åº¦/é“å¾·æ„Ÿ åŸºäº10ä½ä¸­æ–‡è¯„ä»·è€…å¯¹åå­—ä¸­åŒ…å«çš„å­—ç¬¦å¯èƒ½å¸¦æ¥çš„æ¸©æš–ç›¸å…³ç‰¹è´¨çš„ä¸»è§‚è¯„åˆ†ï¼ˆ1åˆ°5åˆ†ï¼‰ã€‚ï¼ˆ1 =æä¸å¯èƒ½å…·æœ‰ï¼Œ3 =ä¸­ç­‰å¯èƒ½æ€§ï¼Œ5 =ææœ‰å¯èƒ½å…·æœ‰ï¼‰
    ï¼ˆâˆšï¼‰NCğŸ‘†: Name competence, åå­—èƒ½åŠ›/è‡ªä¿¡ åŸºäº10ä½ä¸­æ–‡è¯„ä»·è€…å¯¹åå­—ä¸­åŒ…å«çš„å­—ç¬¦å¯èƒ½å¸¦æ¥çš„èƒ½åŠ›ç›¸å…³ç‰¹è´¨çš„ä¸»è§‚è¯„åˆ†ï¼ˆ1åˆ°5åˆ†ï¼‰ã€‚ï¼ˆ1 =æä¸å¯èƒ½å…·å¤‡ï¼Œ3 =å¯èƒ½æ€§ä¸­ç­‰ï¼Œ5 =ææœ‰å¯èƒ½å…·å¤‡ï¼‰ã€‚
    '''
    cn = ChineseNames()
    df_res = cn.compute_name_index(name=name_li, birth=[0] * len(name_li))
    df = df_res[['NU', 'CCU', 'NV', 'NW', 'NC']].copy()
    # å°†dfçš„æ¯ä¸€åˆ—éƒ½è¿›è¡Œæœ€å¤§æœ€å°å½’ä¸€åŒ–
    for col in ['NU', 'CCU']:
        df.loc[:, col] = (df[col] - 1) / (6 - 1)
    for col in ['NV', 'NW', 'NC']:
        df.loc[:, col] = (df[col] - 1) / (5 - 1)
    # å†æ±‚å¹³å‡å€¼
    df.loc[:, 'Nov'] = (df['NU'] + df['CCU'] + df['NV'] + df['NW'] + df['NC']) / 5
    # df['name'] = name_li
    # print(df)
    return df['Nov']


def weighted_average(weights, values):  # å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—åŠ æƒå¹³å‡
    if values is np.nan:
        return np.nan
    try:
        # ç¡®ä¿weightså’Œvaluesé•¿åº¦ç›¸åŒ
        weights = eval(weights)
        # è®¡ç®—åŠ æƒå¹³å‡
        weights = np.array(weights)
        values = np.array(values)
        return np.round(np.sum(weights * values), 4)
    except Exception as e:
        print(e)
    return np.nan


def eval_res(df, num, f_eval):
    if os.path.exists(f_eval):
        df_res = pd.read_csv(f_eval)
    else:
        df_res = pd.DataFrame(columns=['query', 'name', 'exp', 'r_poem', 'backbone', 'method', 'up_w', 'output',
                                       'nov', 'emoc', 'crc', 'lc', 'acc'])
        df_res.to_csv(f_eval, index=False, encoding='utf-8')

    # æ–°é¢–åº¦
    df_nov = eval_Nov(name_li=df['name'].values.tolist()[:num])
    df.loc[:num - 1, 'nov'] = df_nov.values.tolist()
    # print(df_nov.values)

    for i in tqdm(range(num)):
        # è‹¥å·²ç»è®¡ç®—è¿‡ï¼Œåˆ™è·³è¿‡
        df_find = df_res[(df_res['query'] == df.loc[i, 'query'])
                         & (df_res['backbone'] == df.loc[i, 'backbone'])
                         & (df_res['method'] == df.loc[i, 'method'])]
        if df_find.shape[0] > 0:
            continue
        # è¯¥æ–¹æ³•ä¸åœ¨è¯„ä¼°åˆ—è¡¨ä¸­ï¼Œåˆ™è·³è¿‡
        if df.loc[i, 'method'] not in eval(args.method_li):
            continue
        try:
            user_query = df.loc[i, 'query']
            gen_cont = df.loc[i, 'name']
            exp = df.loc[i, 'exp']
            gen_cont_all = '{}ã€‚è§£é‡Šï¼š{}'.format(gen_cont, exp)
            evaluator = Evaluator(user_query=user_query, gen_cont_all=gen_cont_all, gen_cont=gen_cont, exp=exp)
            emoc, crc, lc, acc = evaluator.run()
            df.loc[i, 'emoc'] = str(emoc)
            df.loc[i, 'crc'] = str(crc)
            df.loc[i, 'lc'] = str(lc)
            df.loc[i, 'acc'] = str(acc)
            df_tmp = pd.DataFrame({'query': [user_query],
                                   'name': [gen_cont],
                                   'exp': [exp],
                                   'r_poem': [df.loc[i, 'r_poem']],
                                   'backbone': [df.loc[i, 'backbone']],
                                   'method': [df.loc[i, 'method']],
                                   'up_w': [df.loc[i, 'up_w']],
                                   'output': [df.loc[i, 'output']],
                                   'nov': [df.loc[i, 'nov']],
                                   'emoc': [df.loc[i, 'emoc']],
                                   'crc': [df.loc[i, 'crc']],
                                   'lc': [df.loc[i, 'lc']],
                                   'acc': [df.loc[i, 'acc']]})
            df_tmp.to_csv(f_eval, index=False, encoding='utf-8', mode='a', header=False)
        except Exception as e:
            print(e)
            print('Error in line:', i)
            # time.sleep(30)
            continue


def calc_scores(f_in, f_new, f_summary):
    # é‡æ–°è¯»å–resï¼Œè®¡ç®—å…¶ä»–æŒ‡æ ‡è®¡ç®—
    df = pd.read_csv(f_in)
    # å¤„ç†å¼‚å¸¸å€¼
    # å°†crcé‡Œé¢lenå°äº5çš„å»æ‰
    df = df[df['crc'].apply(lambda x: len(eval(x)) == 5)]
    df = df[df['lc'].apply(lambda x: len(eval(x)) == 5)]
    df = df[df['emoc'].apply(lambda x: len(eval(x)) == 5)]
    # å°†crcå’Œlcé‡Œé¢çš„nanå€¼å»æ‰
    df = df[~df['acc'].isna()]
    df = df[~df['crc'].isna()]
    df = df[~df['lc'].isna()]
    df = df[~df['emoc'].isna()]
    # åˆ é™¤[]é‡Œé¢å­˜åœ¨strçš„è¡Œ
    df = df[~df['crc'].apply(lambda x: any([isinstance(i, str) for i in eval(x)]))]
    df = df[~df['lc'].apply(lambda x: any([isinstance(i, str) for i in eval(x)]))]
    df = df[~df['emoc'].apply(lambda x: any([isinstance(i, str) for i in eval(x)]))]

    # é¢„å¤„ç†
    def normalize_to_100(x):
        if isinstance(x, str):
            x = eval(x)
        x = np.array(x, dtype=float)  # è½¬æˆ NumPy æ•°ç»„ä»¥ä¾¿å‘é‡åŒ–å¤„ç†
        x = (x - 0) / (3 - 0) * 100  # åˆ†æ•°èŒƒå›´ï¼š0-3
        x = np.round(x, 4)  # å››èˆäº”å…¥ä¿ç•™ä¸¤ä½å°æ•°
        return list(x)  # è½¬å› list

    def weighted_average(weights, values):  # å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—åŠ æƒå¹³å‡
        if values is np.nan:
            return np.nan
        try:
            # ç¡®ä¿weightså’Œvaluesé•¿åº¦ç›¸åŒ
            weights = eval(weights)
            # è®¡ç®—åŠ æƒå¹³å‡
            weights = np.array(weights)
            values = np.array(values)
            return np.round(np.sum(weights * values) / 1, 4)  # æƒé‡æ€»å’Œä¸º1
        except Exception as e:
            print(e)
        return np.nan

    # EMOC, EMOC(std) [3,2,2,3,1] -> æ ‡å‡†å·®
    df.loc[:, 'emoc_n'] = df.loc[:, 'emoc'].apply(lambda x: normalize_to_100(x))  # å½’ä¸€åŒ–ï¼ˆ0-3ï¼‰åˆ°ï¼ˆ0-100ï¼‰
    df.loc[:, 'emoc_w'] = df.loc[:,['up_w','emoc_n']].apply(lambda row: weighted_average(row['up_w'], row['emoc_n']), axis=1)  # è®¡ç®—åŠ æƒå¹³å‡
    df.loc[:, 'emoc_std'] = df.loc[:, 'emoc_n'].apply(lambda x: np.round(np.std(x), 4))  # æ ‡å‡†å·®ï¼Œå¤šç›®æ ‡ç¨³å®šæ€§
    # CRC
    df.loc[:, 'crc_n'] = df.loc[:, 'crc'].apply(lambda x: normalize_to_100(x))
    df.loc[:, 'crc_avg'] = df.loc[:, 'crc_n'].apply(lambda x: np.round(np.mean(x), 4))
    # LR
    df.loc[:, 'lr_n'] = df.loc[:, 'lc'].apply(lambda x: normalize_to_100(x))
    df.loc[:, 'lr_avg'] = df.loc[:, 'lr_n'].apply(lambda x: np.round(np.mean(x), 4))
    # ACC
    df.loc[:, 'acc_n'] = df.loc[:, 'acc'].apply(
        lambda x: round(sum(eval(x)) / len(eval(x)) * 100, 2))  # å‡†ç¡®ç‡=æ­£ç¡®çš„æ•°é‡/æ€»æ•°*100
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    df[['emoc_w', 'acc_n', 'emoc_std', 'crc_avg', 'lr_avg']] = df[
        ['emoc_w', 'acc_n', 'emoc_std', 'crc_avg', 'lr_avg']].astype(float)
    # IMOC, IMOC(std)
    df.loc[:, 'imp'] = (1 / 3) * df.loc[:, 'acc_n'] + (1 / 3) * df.loc[:, 'crc_avg'] + (1 / 3) * df.loc[:, 'lr_avg']
    df.loc[:, 'imp_std'] = df.loc[:, ['acc_n', 'crc_avg', 'lr_avg']].std(axis=1)  # è®¡ç®—æ ‡å‡†å·®
    # CMOC
    df.loc[:, 'cmoc'] = 0.5 * df.loc[:, 'emoc_w'] + 0.5 * df.loc[:, 'imp']
    df.loc[:, 'cmoc_std'] = df[['emoc_w', 'imp']].std(axis=1)  # è®¡ç®—æ ‡å‡†å·®
    # é‡æ–°ä¿å­˜ç»“æœ
    df_new = df.replace('', np.nan)
    df_new.to_csv(f_new, index=False, encoding='utf-8')

    # è®¡ç®—æ¯ä¸ªæ–¹æ³•çš„å¹³å‡å€¼
    df_need = df[['backbone', 'method',
                  'emoc_w', 'emoc_std',
                  'crc_avg', 'lr_avg', 'acc_n',
                  'imp', 'imp_std',
                  'cmoc', 'cmoc_std']]
    # æŒ‰ç…§backboneå’Œmethodåˆ†ç»„ï¼Œè®¡ç®—æ¯åˆ—çš„å¹³å‡å€¼ï¼Œå­˜å…¥æ–°çš„df
    df_summary = df_need.groupby(['backbone', 'method']).mean().reset_index()

    if os.path.exists(f_summary):
        # è‹¥å·²å­˜åœ¨ç›¸åŒbackboneå’Œmethodçš„æ•°æ®ï¼Œåˆ™ç”¨æ–°çš„æ•°æ®æ›¿æ¢
        df_ori = pd.read_csv(f_summary)
        for i in range(df_summary.shape[0]):
            df_tmp = df_summary.iloc[i, :]
            df_find = df_ori[(df_ori['backbone'] == df_tmp['backbone']) & (df_ori['method'] == df_tmp['method'])]
            if df_find.shape[0] > 0:
                # å¦‚æœæ•°æ®å­˜åœ¨ï¼Œåˆ™æŠŠæ—§çš„æ•°æ®åˆ é™¤
                df_ori = df_ori[~((df_ori['backbone'] == df_tmp['backbone']) & (df_ori['method'] == df_tmp['method']))]
            # å°†æ–°çš„æ•°æ®æ·»åŠ åˆ°df_oriä¸­
            df_add = pd.DataFrame(df_tmp).T
            df_ori = pd.concat([df_ori, df_add], axis=0)
            # ä¿å­˜ç»“æœ
            df_ori.to_csv(f_summary, index=False, encoding='utf-8')
            print('Update scores:', df_tmp['backbone'], df_tmp['method'])
    else:
        # åˆ›å»ºæ–°æ–‡ä»¶å¹¶ä¿å­˜ç»“æœ
        df_summary.to_csv(f_summary, index=False, encoding='utf-8')


def addScoresToCSV():
    # model_li = ['baichuan', 'gemini', 'gpt4o_mini', 'gpt4o', 'gpt4', 'glm4','glm-4-long','glm-4-flash', 'mistral', 'qwen']
    model_li = ['qwen', 'glm4', 'deepseek', 'gemini', 'mistral', 'gpt4o']
    # model_li = ['qwen']
    for m in tqdm(model_li):
        print(f'Evaluate {m}...')
        f_eval_res_emoc = params.f_eval_res_emoc.format(m)  # '0914/eval_results_{}_emoc.csv'
        f_eval_final_res = params.f_eval_final_res.format(m)  # 'final_res/eval_results_{}_final.csv'
        f_scores = params.f_eval_res_scores  # 'eval_results_scores.csv'
        calc_scores(f_in = f_eval_res_emoc, f_new=f_eval_final_res, f_summary = f_scores)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Evaluate the results of the methods.")
    # parser.add_argument("-b", "--backbone", required=True, help="Evaluate the results from the backbone.")
    # parser.add_argument("-m", "--method_li", default="['base','fewshot','CoT','TDB','llm_discussion','query2keyword','magic_moo']",
    #                     help="Evaluate the results from the method.")
    # parser.add_argument("-s1", "--step1", default=True, help="Evaluate the results.")
    # parser.add_argument("-s2", "--step2", default=True, help="Evaluate the final scores.")
    args = parser.parse_args()
    # ====æµ‹è¯•====
    args.step1 = False
    args.step2 = True
    args.backbone = 'gemini' # qwen
    args.method_li = "['magic_moo']" # magic_moo_wo-evalExp
    # ============
    step1 = args.step1
    step2 = args.step2
    # è¯„ä¼°
    if step1:  # åˆ†åˆ«è¯„ä¼°æ¯ä¸ªæ¨¡å‹çš„ç»“æœ
        model = args.backbone  # 'baichuan','qwen', 'mistral', 'gemini', 'glm-4-long','gpt4o',
        print(f'Evaluate {model}...{args.method_li}')
        if 'magic_moo' in args.method_li:
            f = params.test_bl_os + f'magicMOO/magicMOO_{model}.csv'  # todo: ä¿®æ”¹è·¯å¾„
            method = eval(args.method_li)[0]
            if 'wo' in method:
                ab = method.split('_')[-1]
                f = params.test_bl_os + f'magicMOO/magicMOO_{model}_{ab}.csv'  # 'wo-R', 'wo-evalR', 'wo-Imp', 'wo-Exp', 'wo-evalGen'
        else:
            f = params.test_bl_os + f'0818/baseline_{model}.csv'
        f_eval_res = params.f_eval_res.format(model)  # '0914/eval_results_{}.csv'
        f_eval_res_emoc = params.f_eval_res_emoc.format(model)  # '0914/eval_results_{}_emoc.csv'
        df_ = pd.read_csv(f)
        num = df_.shape[0]
        eval_res(df_, num, f_eval_res_emoc)  # è¯„ä¼°
        print('Done!')
    if step2:  # è®¡ç®—æœ€ç»ˆå¾—åˆ†
        addScoresToCSV()
        print('Done!')

    # # å•ç‹¬æµ‹è¯•
    # args.method_li = "['base','fewshot','CoT','TDB','llm_discussion','RAG']"
    # metod = 'RAG'  # base,fewshot,CoT,RAG
    # model = 'glm-4-flash' # 'baichuan','qwen', 'mistral', 'gemini', 'glm-4-flash','gpt4o',
    # f = params.test_bl_os + f'0818/baseline_{model}.csv'
    # f_eval_res = params.f_eval_res.format(model)  # '0818/eval_results_{}.csv'
    # df_ = pd.read_csv(f)
    # print(f'Evaluate {model} {metod}...')
    # num = 20
    # df_ = df_.loc[df_['method'] == metod].reset_index(drop=True)
    # eval_res(df_, num, f_eval_res)
    # addScoresToCSV()
